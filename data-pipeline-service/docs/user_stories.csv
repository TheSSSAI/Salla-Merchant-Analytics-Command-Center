"story_id","epic","title","user_role","description","business_value","priority","story_points","dependencies","acceptance_criteria","technical_tasks","definition_of_done"
"US-001","Authentication & Onboarding","User Registration with Secure Credential Management","New Merchant","As a new merchant, I want to create a secure account using my email and password so that I can establish my identity and access the platform to connect my store.","Primary entry point for customer acquisition; establishes security foundation via Argon2/Bcrypt hashing required for all subsequent data access.","Must Have","3","[]","[{""scenario"":""Successful registration with valid credentials"",""given"":""I am on the registration page with a unique email address"",""when"":""I enter a valid email and a password meeting complexity requirements (10+ chars, mixed case, symbols)"",""then"":""A new user record is created, the password is securely hashed, an access token is issued, and I am redirected to the Salla connection step.""},{""scenario"":""Duplicate email prevention"",""given"":""An account with 'merchant@example.com' already exists"",""when"":""I attempt to register with 'merchant@example.com'"",""then"":""The system rejects the request with a generic error message to prevent enumeration and no new record is created.""}]","[""WI-005: Implement User Registration & Login API"",""WI-003: Implement PostgreSQL Schema with Prisma ORM""]","[""User table created in PostgreSQL with unique email constraint"",""Password hashing implemented using Argon2 or Bcrypt"",""JWT issuance logic verified"",""Unit tests covering validation logic pass with >80% coverage""]"
"US-009","Authentication & Onboarding","Connect Salla Store via OAuth 2.0","Store Owner","As a Store Owner, I want to securely connect my Salla store using OAuth so that the platform can access my sales data without requiring me to share my direct credentials.","Critical conversion step; enables the core data pipeline. Without this, the platform provides zero value to the user.","Must Have","5","[""US-001""]","[{""scenario"":""Successful OAuth Authorization Flow"",""given"":""I am a logged-in user on the 'Connect Store' page"",""when"":""I click 'Connect Salla' and approve permissions on the Salla consent screen"",""then"":""I am redirected back to the app, the OAuth state is validated to prevent CSRF, and my Access/Refresh tokens are encrypted and stored in the database.""},{""scenario"":""Token Encryption at Rest"",""given"":""A successful connection has been made"",""when"":""A database administrator inspects the 'Merchant' table"",""then"":""The Salla access and refresh tokens appear as encrypted strings, not plain text.""}]","[""WI-006: Implement Salla OAuth 2.0 Integration"",""WI-003: Implement PostgreSQL Schema with Prisma ORM""]","[""OAuth callback route handles code exchange"",""State parameter validation implemented for CSRF protection"",""Tokens stored encrypted in PostgreSQL"",""Integration test with Salla mock/sandbox passes""]"
"US-011","Data Ingestion & Pipeline","Select Historical Data Import Depth","Store Owner","As a Store Owner, I want to select how much historical data (12 or 24 months) to import so that I can balance the time-to-value with the depth of analytical insight I require.","Manages user expectations regarding setup time and ensures system resources are allocated efficiently via background processing.","Should Have","3","[""US-009""]","[{""scenario"":""Initiate background import job"",""given"":""I have just connected my Salla store"",""when"":""I select '12 Months' depth and click 'Start Import'"",""then"":""A background job is queued in QStash, my account status updates to 'Syncing', and I am shown a progress dashboard.""},{""scenario"":""Rate limit handling during import"",""given"":""The background worker is fetching data"",""when"":""The Salla API returns a 429 Rate Limit error"",""then"":""The worker pauses execution and retries after the specified 'Retry-After' window without failing the job.""}]","[""WI-008: Develop Historical Data Sync Worker"",""WI-007: Implement Salla Webhook Handler Function""]","[""QStash endpoint configured for long-running jobs"",""Pagination logic handles Salla API cursors"",""Sync status is observable in the UI"",""Data is successfully written to PostgreSQL""]"
"US-022","Deep Analytics Engine","Main Dashboard KPI Visualization","Data Analyst","As a Data Analyst, I want to view high-level KPIs (Total Sales, Orders, AOV) on a central dashboard so that I can quickly assess the store's performance health.","Provides immediate at-a-glance value to the user, justifying the platform utility. Targeted LCP < 2.5s ensures a premium user experience.","Must Have","5","[""US-011""]","[{""scenario"":""Dashboard rendering performance"",""given"":""I have 100,000 order records in the database"",""when"":""I load the main dashboard"",""then"":""The KPI grid renders the aggregated metrics in less than 2.5 seconds (LCP)."",""performance_metric"":""p95 API response < 200ms""},{""scenario"":""Date range filtering"",""given"":""I am viewing the dashboard"",""when"":""I change the global date filter from 'Last 7 Days' to 'Last 30 Days'"",""then"":""All KPI widgets automatically refresh to reflect the new date range without a full page reload.""}]","[""WI-014: Construct Main Analytics Dashboard"",""WI-013: Build Reusable Chart Components"",""WI-004: Configure ClickHouse OLAP Schema & Connection""]","[""ClickHouse aggregation queries optimized"",""Frontend skeleton loading states implemented"",""Global state management (Zustand) wired to API calls"",""Visual regression tests pass for Light/Dark mode""]"
"US-025","Deep Analytics Engine","Sales Trend Analysis with Granular Grouping","Store Owner","As a Store Owner, I want to group sales trend charts by hour, day, week, or month so that I can identify both intraday shopping patterns and long-term seasonal trends.","Enables tactical decision making (e.g., when to send emails) and strategic planning (e.g., inventory stocking).","Should Have","5","[""US-022""]","[{""scenario"":""Dynamic aggregation grouping"",""given"":""I am viewing the Sales Trend chart"",""when"":""I switch the grouping from 'Day' to 'Hour'"",""then"":""The chart re-renders showing hourly data points for the selected period."",""performance_metric"":""Query executes in ClickHouse < 200ms""},{""scenario"":""Zero-fill missing data"",""given"":""I selected a week where no sales occurred on Tuesday"",""when"":""I view the daily trend"",""then"":""Tuesday is displayed on the X-axis with a value of 0, ensuring the time series is continuous.""}]","[""WI-010: Develop Sales Trend API Endpoint"",""WI-013: Build Reusable Chart Components""]","[""API endpoint accepts grouping parameters"",""Chart components handle dynamic X-axis formatting"",""Timezone handling ensures accurate daily buckets"",""Unit tests cover aggregation logic""]"
"US-035","AI Assistant (RAG)","Natural Language Data Querying","Store Owner","As a Store Owner, I want to ask questions about my sales data in plain language (e.g., 'Best selling product last week?') so that I can get insights without navigating complex report filters.","Reduces the barrier to entry for advanced analytics and serves as a major competitive differentiator.","Could Have","8","[""US-022""]","[{""scenario"":""Successful RAG query"",""given"":""I am on the AI Assistant page"",""when"":""I ask 'What is my average order value for last month?'"",""then"":""The system retrieves the relevant context, queries the database, and returns a formatted text answer.""},{""scenario"":""PII Protection"",""given"":""I ask a question related to customer data"",""when"":""The system processes the prompt for the LLM"",""then"":""Any PII (Personally Identifiable Information) is stripped or anonymized before being sent to the OpenAI API.""}]","[""WI-016: Develop RAG Query Service"",""WI-015: Implement Vector Embedding Pipeline""]","[""pgvector extension enabled and populated"",""OpenAI API circuit breaker implemented"",""Prompt engineering validates SQL generation safety"",""Response formatting handles markdown/charts""]"
"US-043","Cart Recovery Module","Rich Text Email Template Creation","Marketer","As a Marketer, I want to design email templates using a rich text editor with dynamic variables so that I can create personalized recovery emails that match my brand.","Essential for the cart recovery feature; personalized emails have significantly higher conversion rates.","Should Have","5","[""US-001""]","[{""scenario"":""Create template with variables"",""given"":""I am in the Template Editor"",""when"":""I insert the '{{customer_name}}' variable and bold specific text"",""then"":""The template is saved with HTML formatting and variable placeholders preserved.""},{""scenario"":""Security sanitization"",""given"":""I attempt to paste a malicious script into the editor"",""when"":""I save the template"",""then"":""The backend sanitizes the HTML, removing the script tags before storage.""}]","[""WI-017: Implement Email Template Editor""]","[""TipTap/Quill editor integrated"",""HTML sanitization middleware active"",""Preview mode renders variable placeholders correctly"",""CRUD operations for templates functional""]"
"US-041","Cart Recovery Module","Automated Cart Recovery Scheduler","Marketer","As a Marketer, I want to define a schedule for sending recovery emails to abandoned carts so that revenue recovery happens automatically without manual intervention.","Directly drives revenue recovery; automating this process is the core value prop of the recovery module.","Must Have","8","[""US-043"",""US-011""]","[{""scenario"":""Schedule email execution"",""given"":""A cart has been abandoned for 1 hour (threshold met)"",""when"":""The scheduled cron job runs"",""then"":""The system identifies the cart, verifies it hasn't been converted, and triggers the email dispatch via Postmark.""},{""scenario"":""Suppression list adherence"",""given"":""A user has previously unsubscribed"",""when"":""Their cart is abandoned"",""then"":""The scheduler skips sending the email and logs the suppression event.""}]","[""WI-018: Develop Recovery Campaign Scheduler"",""WI-007: Implement Salla Webhook Handler Function""]","[""Cron job configured in Vercel/QStash"",""Logic handles abandonment thresholds correctly"",""Postmark integration verified"",""Audit logs capture sent/skipped statuses""]"