"story_id","epic","title","user_role","description","business_value","priority","story_points","dependencies","acceptance_criteria","technical_tasks","definition_of_done"
"US-004","Core Infrastructure & Authentication","Secure Merchant Authentication","Merchant (Store Owner/Admin)","As a Merchant, I want to securely log in using a standardized authentication system so that I can access my private store data while preventing unauthorized access.","Establishes the security perimeter required for multi-tenancy and data privacy compliance, forming the prerequisite for all system access.","Must Have","5","[]","[{""scenario"":""Successful Login via JWT"",""given"":""A registered user exists in the PostgreSQL database"",""when"":""The user submits valid credentials to the login endpoint"",""then"":""The system issues a signed JWT Access Token and sets a secure HttpOnly Refresh Token cookie""},{""scenario"":""Role-Based Access Enforcement"",""given"":""A user has an 'Analyst' role"",""when"":""They attempt to access an 'Admin-only' route protected by RBAC middleware"",""then"":""The system returns a 403 Forbidden response and denies access""},{""scenario"":""Session Management & Rotation"",""given"":""A user's Access Token has expired"",""when"":""The client makes a request with a valid Refresh Token"",""then"":""The system rotates the Refresh Token and issues a new Access Token seamlessly""}]","[""WI-001: Initialize Next.js Repository"",""WI-002: Design & Implement PostgreSQL Schema (Prisma)"",""WI-004: Implement JWT Authentication Service"",""WI-005: Develop RBAC Middleware""]","[""JWT implementation uses RS256 signing"",""HttpOnly cookies are used for refresh tokens"",""80% unit test coverage on auth logic"",""RBAC middleware successfully blocks unauthorized routes""]"
"US-009","Salla Integration & Onboarding","Connect Salla Store via OAuth","Store Owner","As a Store Owner, I want to connect my Salla store using a secure OAuth 2.0 flow so that the platform can import my products, orders, and customer data for analysis.","Enables the fundamental data ingestion capability of the platform, converting a registered user into an active tenant.","Must Have","5","[""US-004""]","[{""scenario"":""Successful OAuth Authorization"",""given"":""A logged-in user initiates the connection flow"",""when"":""They approve the application on the Salla consent screen"",""then"":""The system exchanges the authorization code for tokens and encrypts them (AES-256) in the database""},{""scenario"":""CSRF Protection"",""given"":""A malicious actor attempts to forge an OAuth callback"",""when"":""The callback contains an invalid or mismatched 'state' parameter"",""then"":""The system rejects the request and logs a security incident""},{""scenario"":""Token Refresh Handling"",""given"":""Stored Salla access tokens have expired"",""when"":""A background job attempts to fetch data"",""then"":""The system automatically refreshes the Salla tokens using the stored refresh token""}]","[""WI-006: Implement Salla OAuth 2.0 Flow"",""WI-002: Design & Implement PostgreSQL Schema (Prisma)""]","[""OAuth State parameter validation implemented"",""Tokens stored with AES-256 encryption"",""Integration tests with mocked Salla API pass"",""Error handling for Salla API rate limits implemented""]"
"US-012","Salla Integration & Onboarding","Historical Data Synchronization","Store Owner","As a Store Owner, I want my historical sales data (12-24 months) to be imported automatically in the background so that I can immediately view meaningful analytics without manual data entry.","Provides immediate analytical value to new users by populating dashboards with historical context, reducing time-to-value.","Must Have","8","[""US-009""]","[{""scenario"":""Background Job Initiation"",""given"":""A user completes Salla OAuth connection"",""when"":""The system triggers the onboarding event"",""then"":""A QStash job is scheduled to fetch historical orders and customers""},{""scenario"":""Rate Limit Handling"",""given"":""The synchronization job hits Salla API rate limits (429)"",""when"":""The error occurs"",""then"":""The job pauses and retries with exponential backoff logic""},{""scenario"":""Sync Status Feedback"",""given"":""A sync is in progress"",""when"":""The user visits the dashboard"",""then"":""A UI indicator displays the current sync status (In Progress / Completed)""}]","[""WI-007: Develop Historical Data Sync Worker""]","[""Job handles pagination for >10,000 orders"",""QStash configured with correct timeout and retry policies"",""Data is correctly mapped from Salla JSON to Prisma schema"",""Sync status is observable in the UI""]"
"US-059","Data Pipeline & Real-time Sync","Real-time Data Ingestion Pipeline","Data Analyst","As a Data Analyst, I want sales and cart events to be updated in near real-time (<5 mins) so that my reports reflect the current state of the business.","Ensures data freshness for accurate reporting and timely automated actions (like cart recovery), preventing stale insights.","Must Have","13","[""US-009""]","[{""scenario"":""Webhook Processing"",""given"":""A customer places an order on the Salla store"",""when"":""Salla sends an 'order.created' webhook"",""then"":""The system validates the HMAC signature and upserts the order to the OLTP database""},{""scenario"":""CDC to OLAP Propagation"",""given"":""New data is written to PostgreSQL (OLTP)"",""when"":""The CDC pipeline processes the change"",""then"":""The data is transformed and inserted into ClickHouse (OLAP) within 5 minutes""},{""scenario"":""Duplicate Event Handling"",""given"":""Salla sends the same webhook twice"",""when"":""The system processes the second event"",""then"":""The operation is idempotent and does not create duplicate records""}]","[""WI-008: Implement Salla Webhook Handler"",""WI-009: Build CDC Pipeline to ClickHouse"",""WI-003: Configure ClickHouse Schema & Client""]","[""HMAC signature verification implemented"",""ClickHouse Batch ingestion latency < 5 mins verified"",""Idempotency tests passed"",""Dead Letter Queue (DLQ) configured for failed events""]"
"US-022","Analytics & Visualization","Sales Performance Dashboard","Merchant","As a Merchant, I want to view interactive charts of my sales trends filtered by date ranges so that I can visually identify performance patterns and anomalies.","Delivers the core analytical product value, replacing manual spreadsheet tracking with automated, visual insights.","Must Have","8","[""US-059""]","[{""scenario"":""Date Range Filtering"",""given"":""The dashboard is loaded"",""when"":""User selects 'Last 30 Days' from the date picker"",""then"":""The API queries ClickHouse and updates the Recharts visualization within 200ms""},{""scenario"":""Dynamic Grouping"",""given"":""Sales data exists for the year"",""when"":""User toggles grouping from 'Daily' to 'Monthly'"",""then"":""The chart aggregates the data accordingly without page reload""},{""scenario"":""Tenant Isolation"",""given"":""User A requests analytics data"",""when"":""The API constructs the database query"",""then"":""The query strictly scopes results to User A's merchant_id""}]","[""WI-010: Develop Sales Trend Analysis API"",""WI-011: Implement Recharts Components for Dashboards""]","[""API response time P95 < 200ms confirmed"",""Charts are responsive on mobile devices"",""SQL injection prevention via parameterized queries confirmed"",""LCP < 2.5s on dashboard page""]"
"US-035","AI Assistant (RAG)","Natural Language Data Querying","Store Owner","As a Store Owner, I want to ask questions about my data in plain language (e.g., 'What were my sales last Friday?') so that I can get quick answers without complex filtering.","Lowers the barrier to entry for data analysis, allowing non-technical users to extract deep value from the platform.","Should Have","13","[""US-022""]","[{""scenario"":""Successful RAG Query"",""given"":""The user asks 'Top 5 products by revenue'"",""when"":""The request is processed"",""then"":""The system retrieves schema context via pgvector, generates SQL via LLM, and returns the correct data result""},{""scenario"":""Contextual Understanding"",""given"":""The system has store product metadata embedded"",""when"":""The user asks a question using specific product terminology"",""then"":""The AI correctly maps the terms to the database schema""},{""scenario"":""Security/PII Protection"",""given"":""The user asks a question"",""when"":""The prompt is constructed for OpenAI"",""then"":""Customer PII is scrubbed or excluded from the prompt sent to the external LLM""}]","[""WI-012: Configure pgvector & Embedding Pipeline"",""WI-013: Develop AI Chat API with RAG""]","[""pgvector extension enabled and working"",""Prompt injection safeguards tested"",""Streaming response implemented for UX"",""Embeddings update automatically on schema changes""]"
"US-041","Cart Recovery Automation","Automated Cart Recovery Campaigns","Marketer","As a Marketer, I want to configure and schedule automated email sequences for abandoned carts so that I can recover lost revenue without manual intervention.","Directly drives revenue generation for the merchant, providing a clear ROI for the platform.","Must Have","13","[""US-059""]","[{""scenario"":""Recovery Job Scheduling"",""given"":""A cart is marked as abandoned"",""when"":""The configured delay time (e.g., 1 hour) passes"",""then"":""QStash triggers the email worker to send the recovery email""},{""scenario"":""Purchase Conversion Check"",""given"":""A recovery email is scheduled"",""when"":""The customer completes the purchase before the scheduled time"",""then"":""The scheduled job detects the completed order and cancels the email sending""},{""scenario"":""Template Rendering"",""given"":""A customized email template exists"",""when"":""The email is generated"",""then"":""Dynamic variables (customer name, cart items) are correctly substituted in the HTML""}]","[""WI-014: Implement Rich Text Email Template Editor"",""WI-015: Develop Recovery Job Scheduler""]","[""Rich text editor outputs sanitized HTML"",""Scheduling logic handles timezone differences"",""Integration with Postmark API verified"",""Suppression list logic (unsubscribes) implemented""]"