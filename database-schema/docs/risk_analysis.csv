"risk_id","risk_category","risk_description","probability","impact","risk_score","priority_level","affected_tasks","root_cause","mitigation_strategy","contingency_plan","monitoring_trigger","owner","due_date","status"
"RISK-001","Technical","AI Hallucination and SQL Injection vulnerability via RAG pipeline (WI-AI-002), potentially generating incorrect analytics or exposing unauthorized data.","4","5","20","High","WI-AI-002 (Implement NLQ API), WI-AI-003 (Develop AI Chat Component)","Inherent probabilistic nature of LLMs combined with dynamic SQL generation requirements against tenant data.","Implement strict read-only database user for AI queries; Restrict LLM context to specific schema subsets; Validate generated SQL against a whitelist of allowed operations before execution.","Fallback to pre-defined static reports if confidence score of generated SQL is low; Implement 'human-in-the-loop' feedback mechanism.","SQL execution errors > 1% on AI endpoints; User feedback flagging 'Incorrect Data'.","AI/ML Engineer","2025-06-15","Not Started"
"RISK-002","External","Salla API Rate Limiting leading to Historical Data Sync failures (WI-SYNC-001), causing incomplete datasets and onboarding stall.","5","4","20","High","WI-SYNC-001 (Historical Data Sync Worker), WI-SYNC-002 (Sync Progress UI)","Aggressive pagination requirements for historical data extraction against strict external API limits (Salla).","Implement robust exponential backoff using QStash retry logic; Respect `X-RateLimit` headers strictly; decouple fetch and insert operations.","Implement 'Resume Sync' capability to pick up from last successful page; Notify users of extended wait times for large stores.","429 HTTP response rate > 5% from Salla API client.","Backend Lead","2025-06-01","Not Started"
"RISK-003","Technical","Serverless Database Connection Exhaustion (PostgreSQL) causing API failures under load or concurrent sync jobs.","4","4","16","High","WI-AUTH-001, WI-SYNC-001, WI-DATA-002","Serverless functions scaling horizontally (Vercel) opening too many direct connections to Postgres.","Mandate use of connection pooling (e.g., Supabase Transaction Pool or Neon pooling); Configure Prisma `connection_limit` based on pool size.","Throttle QStash concurrency for background jobs to reduce simultaneous DB load.","Database 'max_connections' reached errors in logs; API latency spikes.","DevOps Engineer","2025-05-25","Not Started"
"RISK-004","Data","Data Pipeline Latency exceeding 5-minute requirement (REQ-DATA-002), resulting in stale analytics and user mistrust.","3","4","12","Medium","WI-DATA-003 (ClickHouse Loader), WI-REP-001 (Dashboard KPI API)","Inefficient CDC event processing or ClickHouse insertion bottlenecks (network/batching issues).","Optimize ClickHouse Loader to use aggressive buffering/batching; Ensure QStash is configured for high-throughput delivery.","Scale up worker concurrency; temporarily switch dashboard to query Postgres for real-time critical metrics (hybrid query approach).","Lag between `event_created_at` and `insertion_time` > 300 seconds.","Data Engineer","2025-06-10","Not Started"
"RISK-005","Security","Cross-Tenant Data Leakage via API or AI queries due to improper scoping of Merchant ID.","3","5","15","High","WI-RBAC-001 (Middleware), WI-REP-001 (KPI API), WI-AI-002 (NLQ API)","Reliance on manual `where` clauses in code rather than Row Level Security (RLS) enforcement at the database level.","Implement comprehensive integration tests specifically checking for cross-tenant access; Enforce strict code review checklist for all Prisma/SQL queries.","Emergency shutdown of API endpoints; Rollback to last known secure deployment; Incident response protocol activation.","Audit logs showing User ID accessing resources associated with a different Merchant ID.","Security Engineer","2025-05-30","Not Started"
"RISK-006","Operational","LLM Cost Escalation due to high volume of RAG queries or inefficient prompt engineering.","4","3","12","Medium","WI-AI-002, WI-AI-001","Lack of caching or token usage limits on open-ended AI chat features.","Implement strict rate limiting on AI endpoints; Cache similar queries/responses; Use smaller/cheaper models for embedding generation.","Disable AI features for lower-tier users; Switch to a budget-capped API key.","Daily OpenAI spend exceeding budget threshold.","Product Owner","2025-06-20","Not Started"