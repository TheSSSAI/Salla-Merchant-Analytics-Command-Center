"risk_id","risk_category","risk_description","probability","impact","risk_score","priority_level","affected_tasks","root_cause","mitigation_strategy","contingency_plan","monitoring_trigger","owner","due_date","status"
"RISK-TEC-001","Technical","LLM-generated SQL queries for the AI Assistant may contain hallucinations or invalid syntax, potentially exposing data or causing query execution failures in ClickHouse.","4","5","20","High","WI-AI-002 (NLQ to SQL Translation Service)","Inherent non-deterministic nature of LLMs combined with complex analytical schema context.","Implement a strict SQL validation layer that parses generated queries against an allowed syntax whitelist. Use a read-only database user for AI queries with strict Row-Level Security (RLS) scopes.","Fallback to pre-defined parameterized query templates for common questions if dynamic generation fails validation.","SQL syntax error rate > 5% on AI query endpoint.","AI Backend Lead","2023-11-15","Not Started"
"RISK-SEC-001","Security","Cross-tenant data leakage via the AI Assistant due to insufficient context isolation in the RAG pipeline or Prompt Injection attacks.","3","5","15","High","WI-AI-002, WI-AUTH-003","Failure to rigidly enforce merchant_id constraints within the vector search or the SQL generation prompt context.","Enforce 'merchant_id' filtering at the database driver level (pgvector and ClickHouse) regardless of LLM output. Implement an input sanitization layer to strip prompt injection patterns.","Immediate disablement of AI features globally via feature flag if leakage is detected.","Detection of queries attempting to access merchant_ids not matching the authenticated user token.","Security Architect","2023-11-10","In Progress"
"RISK-OPS-001","Operational","Serverless function timeouts on Vercel during heavy ETL processing of Salla historical data imports.","5","3","15","High","WI-DATA-003 (CDC Pipeline Worker Implementation)","Vercel's strict execution time limits (usually 10s-60s) conflicting with long-running historical data transformation and batch insertion.","Implement strict pagination and micro-batching. Decouple the ingestion trigger from processing using Upstash QStash to break large jobs into hundreds of small, independent function invocations.","Deploy a dedicated containerized worker (e.g., on Railway or AWS Fargate) for historical imports if serverless limits are insurmountable.","Vercel Function Invocation Timeout errors exceeding 1% of total executions.","Lead DevOps Engineer","2023-11-05","In Progress"
"RISK-EXT-001","External","Salla Webhook bursts during high-traffic sales events causing throttling or data loss before ingestion.","4","4","16","High","WI-DATA-001 (Salla Webhook Receiver)","Synchronous processing logic or database contention preventing the API from acknowledging webhooks within the provider's timeout window.","Implement a 'Fan-out' pattern: The webhook receiver does strictly zero processing other than signature validation and pushing the raw payload to Upstash QStash. Processing happens asynchronously.","Implement a reconciliation cron job that queries the Salla API for 'modified_since' to catch any missed events.","API Response Time > 200ms or non-200 responses on the webhook endpoint.","Backend Engineer","2023-11-01","Not Started"
"RISK-QLT-001","Quality","Data freshness KPI (< 5 mins) failure due to latency in the Upstash-to-ClickHouse pipeline or ClickHouse merge delays.","3","3","9","Medium","WI-DATA-002, WI-DATA-003","Queue congestion or inefficient ClickHouse `ReplacingMergeTree` deduplication strategies under load.","Optimize ClickHouse schema partitioning by month/merchant. Tune QStash parallelism settings. Use 'Buffer' tables in ClickHouse for immediate visibility if MergeTree lag is high.","Display 'Last Updated' timestamp prominently on dashboards to manage user expectations regarding data staleness.","End-to-end latency metric (EventTime vs IngestionTime) exceeding 300 seconds.","Data Engineer","2023-11-20","Not Started"
"RISK-TEC-002","Technical","Cold start latency on Vercel Edge functions causing violations of the 200ms p95 response time requirement.","5","2","10","Medium","WI-AUTH-003 (Next.js Middleware for RBAC)","Initialization overhead of database connections (Prisma) inside serverless functions on intermittent traffic.","Utilize Prisma Accelerate (connection pooling) or edge-compatible drivers. Implement aggressive HTTP caching headers where possible. Minimize bundle size of edge middleware.","Relax p95 requirement to 500ms for initial non-cached requests; keep 200ms for sustained traffic.","Vercel Analytics reporting p95 LCP > 200ms.","Frontend Lead","2023-11-25","Not Started"